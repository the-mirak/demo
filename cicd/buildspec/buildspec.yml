version: 0.2

phases:
  install:
    runtime-versions:
      python: 3.9
    commands:
      - echo "Installing dependencies..."
      - curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.23.7/2022-06-29/bin/linux/amd64/kubectl
      - chmod +x kubectl
      - mv kubectl /usr/local/bin/
      - curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.21.2/2021-07-05/bin/linux/amd64/aws-iam-authenticator
      - chmod +x aws-iam-authenticator
      - mv aws-iam-authenticator /usr/local/bin/
      - yum install -y jq gettext
      - echo "Installing eksctl..."
      - curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
      - mv /tmp/eksctl /usr/local/bin
      - eksctl version

  pre_build:
    commands:
      - echo "Setting up environment variables..."
      - REPOSITORY_URI=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/streamlit-app
      - COMMIT_HASH=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7)
      - IMAGE_TAG=${COMMIT_HASH:=latest}
      - APP_NAME=streamlit-app
      - DOCKERFILE_PATH=Dockerfile
      - ENABLE_CACHE=true
      - echo "Checking CodeBuild role permissions..."
      - aws sts get-caller-identity
      - echo "Updating kubeconfig..."
      - aws eks update-kubeconfig --name $EKS_CLUSTER_NAME --region $AWS_REGION
      - kubectl config view
      - echo "Setting up EKS auth ConfigMap..."
      - chmod +x cicd/scripts/setup-eks-auth.sh
      - |
        ./cicd/scripts/setup-eks-auth.sh --eks-cluster $EKS_CLUSTER_NAME --force || {
          echo "Warning: EKS auth setup failed, but continuing with the build..."
          echo "CodeBuild role will be used directly through IRSA, no need to update aws-auth ConfigMap"
        }
      - |
        kubectl get svc || echo "Warning: Could not get services, but continuing with the build..."
      - echo "Creating S3 bucket for context if it doesn't exist..."
      - S3_BUCKET=kaniko-context-$AWS_ACCOUNT_ID-$AWS_REGION
      - aws s3api create-bucket --bucket $S3_BUCKET --region $AWS_REGION --create-bucket-configuration LocationConstraint=$AWS_REGION || true
      - echo "Preparing application context..."
      - tar -czf /tmp/$APP_NAME.tar.gz -C app .
      - aws s3 cp /tmp/$APP_NAME.tar.gz s3://$S3_BUCKET/
      - echo "Running pre-deployment script..."
      - chmod +x cicd/scripts/pre_deploy.sh
      - ./cicd/scripts/pre_deploy.sh

  build:
    commands:
      - echo "Build started on $(date)"
      - echo "Building the container image using Kaniko..."
      - echo "Setting up IRSA for Kaniko..."
      - |
        # Get OIDC provider ID from EKS cluster
        OIDC_PROVIDER_ID=$(aws eks describe-cluster --name $EKS_CLUSTER_NAME --query "cluster.identity.oidc.issuer" --output text | cut -d'/' -f5)
        echo "OIDC Provider ID: $OIDC_PROVIDER_ID"
        
        # Check if OIDC provider exists
        OIDC_PROVIDER_EXISTS=$(aws iam list-open-id-connect-providers | grep $OIDC_PROVIDER_ID || echo "false")
        
        if [ "$OIDC_PROVIDER_EXISTS" = "false" ]; then
          echo "OIDC provider does not exist. Creating it..."
          eksctl utils associate-iam-oidc-provider --cluster $EKS_CLUSTER_NAME --approve
        else
          echo "OIDC provider already exists"
        fi
        
        # Create trust policy for IRSA - simplified to match what works manually
        echo "Creating trust policy for IRSA..."
        cat > /tmp/kaniko-trust-policy.json << EOF
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Allow",
              "Principal": {
                "Federated": "arn:aws:iam::$AWS_ACCOUNT_ID:oidc-provider/oidc.eks.$AWS_REGION.amazonaws.com/id/$OIDC_PROVIDER_ID"
              },
              "Action": "sts:AssumeRoleWithWebIdentity",
              "Condition": {
                "StringEquals": {
                  "oidc.eks.$AWS_REGION.amazonaws.com/id/$OIDC_PROVIDER_ID:sub": "system:serviceaccount:default:kaniko-builder"
                }
              }
            }
          ]
        }
        EOF
        
        # Create or update the IAM role
        echo "Creating or updating IAM role..."
        aws iam create-role --role-name kaniko-ecr-push-role --assume-role-policy-document file:///tmp/kaniko-trust-policy.json || aws iam update-assume-role-policy --role-name kaniko-ecr-push-role --policy-document file:///tmp/kaniko-trust-policy.json
        
        # Attach policies to the role - using AWS managed policies that are known to work
        echo "Attaching policies to the role..."
        aws iam attach-role-policy --role-name kaniko-ecr-push-role --policy-arn arn:aws:iam::aws:policy/AmazonECR-FullAccess || true
        aws iam attach-role-policy --role-name kaniko-ecr-push-role --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess || true
        
        # Verify the role and its trust policy
        echo "Verifying IAM role and trust policy..."
        aws iam get-role --role-name kaniko-ecr-push-role --query 'Role.AssumeRolePolicyDocument' --output json
      - echo "Checking if ECR repositories exist..."
      - |
        # Check if streamlit-app repository exists
        APP_REPO_EXISTS=$(aws ecr describe-repositories --repository-names $APP_NAME 2>/dev/null || echo "false")
        if [ "$APP_REPO_EXISTS" = "false" ]; then
          echo "Creating $APP_NAME ECR repository..."
          aws ecr create-repository --repository-name $APP_NAME
        else
          echo "$APP_NAME ECR repository already exists"
        fi
        
        # Check if kaniko-cache repository exists
        CACHE_REPO_EXISTS=$(aws ecr describe-repositories --repository-names kaniko-cache 2>/dev/null || echo "false")
        if [ "$CACHE_REPO_EXISTS" = "false" ]; then
          echo "Creating kaniko-cache ECR repository..."
          aws ecr create-repository --repository-name kaniko-cache
        else
          echo "kaniko-cache ECR repository already exists"
        fi
      - echo "Applying Kaniko service account..."
      - envsubst < kubernetes/kaniko-service-account.yaml > kubernetes/kaniko-service-account-updated.yaml
      - kubectl apply -f kubernetes/kaniko-service-account-updated.yaml
      - echo "Verifying service account configuration..."
      - kubectl get serviceaccount kaniko-builder -o yaml
      - echo "Creating Kaniko pod..."
      - kubectl delete pod ${APP_NAME}-kaniko-builder --ignore-not-found=true
      - envsubst < kubernetes/kaniko-pod.yaml > kubernetes/kaniko-pod-updated.yaml
      - kubectl apply -f kubernetes/kaniko-pod-updated.yaml
      - echo "Verifying pod configuration..."
      - kubectl get pod ${APP_NAME}-kaniko-builder -o yaml
      - echo "Checking pod environment variables..."
      - kubectl exec ${APP_NAME}-kaniko-builder -c kaniko -- env || echo "Could not check environment variables, pod may not be ready yet"
      - echo "Checking service account token mount..."
      - kubectl exec ${APP_NAME}-kaniko-builder -c kaniko -- ls -la /var/run/secrets/eks.amazonaws.com/serviceaccount/ || echo "Could not check token mount, pod may not be ready yet"
      - echo "Waiting for Kaniko pod to complete..."
      - kubectl wait --for=condition=Ready pod/${APP_NAME}-kaniko-builder --timeout=60s || true
      - kubectl logs -f ${APP_NAME}-kaniko-builder || true
      - echo "Waiting for Kaniko build to complete..."
      - |
        # Wait for the pod to complete with a timeout
        TIMEOUT=300
        START_TIME=$(date +%s)
        while true; do
          POD_STATUS=$(kubectl get pod ${APP_NAME}-kaniko-builder -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
          CURRENT_TIME=$(date +%s)
          ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
          
          if [ "$POD_STATUS" = "Succeeded" ]; then
            echo "Build succeeded!"
            break
          elif [ "$POD_STATUS" = "Failed" ]; then
            echo "Build failed! Checking logs..."
            kubectl logs ${APP_NAME}-kaniko-builder
            kubectl describe pod ${APP_NAME}-kaniko-builder
            exit 1
          elif [ $ELAPSED_TIME -gt $TIMEOUT ]; then
            echo "Build timed out after $TIMEOUT seconds!"
            kubectl logs ${APP_NAME}-kaniko-builder
            kubectl describe pod ${APP_NAME}-kaniko-builder
            exit 1
          fi
          
          echo "Waiting for build to complete... Current status: $POD_STATUS, elapsed time: $ELAPSED_TIME seconds"
          sleep 5
        done

  post_build:
    commands:
      - echo "Build completed on $(date)"
      - echo "Update Kubernetes deployment..."
      - envsubst < kubernetes/streamlit-deployment.yaml > kubernetes/streamlit-deployment-updated.yaml
      - kubectl apply -f kubernetes/streamlit-deployment-updated.yaml
      - echo "Waiting for deployment to stabilize..."
      - kubectl rollout status deployment/streamlit-app --timeout=300s
      - echo "Cleaning up Kaniko pod..."
      - kubectl delete pod ${APP_NAME}-kaniko-builder
      - echo "Deployment completed successfully!"
      - echo "Running post-deployment verification..."
      - chmod +x cicd/scripts/post_deploy.sh
      - ./cicd/scripts/post_deploy.sh

artifacts:
  files:
    - kubernetes/streamlit-deployment-updated.yaml
    - kubernetes/kaniko-pod-updated.yaml
    - appspec.yml
    - cicd/scripts/post_deploy.sh
  discard-paths: no